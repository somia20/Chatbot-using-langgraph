{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6946d1b1-b6fc-4412-97ce-19d0f0e5a4d6",
   "metadata": {},
   "source": [
    "MESSAGES STATE TEXT TO SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b82d98-a99c-4936-ae7c-af54a792c4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSISDNs read from file: ['9123456789', '9087654321', '9555555555', '9444444444']\n",
      "\n",
      "Question: What are the top 3 products by sales?\n",
      "--------------------------------------------------\n",
      "MSISDNs being used: ['9123456789', '9087654321', '9555555555', '9444444444']\n",
      "Generated SQL Query: Here is the SQL query to answer the question:\n",
      "SELECT \n",
      "  p.product_name, \n",
      "  COUNT(cp.product_id) AS sales_count\n",
      "FROM \n",
      "  customer_purchases cp \n",
      "  INNER JOIN products p ON cp.product_id = p.product_id\n",
      "WHERE \n",
      "  cp.msisdn IN ('9123456789', '9087654321', '9555555555', '9444444444')\n",
      "GROUP BY \n",
      "  p.product_name\n",
      "ORDER BY \n",
      "  sales_count DESC\n",
      "LIMIT 3;\n",
      "Validated SQL Query: SELECT\n",
      "p.product_name,\n",
      "COUNT(cp.product_id) AS sales_count\n",
      "FROM\n",
      "customer_purchases cp\n",
      "INNER JOIN products p ON cp.product_id = p.product_id\n",
      "WHERE\n",
      "cp.msisdn IN ('9123456789', '9087654321', '9555555555', '9444444444')\n",
      "GROUP BY\n",
      "p.product_name\n",
      "ORDER BY\n",
      "sales_count DESC\n",
      "LIMIT 3;\n",
      "Executing SQL Query: SELECT\n",
      "p.product_name,\n",
      "COUNT(cp.product_id) AS sales_count\n",
      "FROM\n",
      "customer_purchases cp\n",
      "INNER JOIN products p ON cp.product_id = p.product_id\n",
      "WHERE\n",
      "cp.msisdn IN ('9123456789', '9087654321', '9555555555', '9444444444')\n",
      "GROUP BY\n",
      "p.product_name\n",
      "ORDER BY\n",
      "sales_count DESC\n",
      "LIMIT 3;\n",
      "Execution Result: [('Data Pack 3GB', 3), ('Data Pack 1GB', 2), ('Unlimited Calls', 2)]\n",
      "Answer: Here's a conversational response that meets the requirements:\n",
      "\n",
      "\"Hey there! Based on our sales data, the top 3 products by sales are:\n",
      "\n",
      "1. **Data Pack 3GB**, which has been sold **3 times**. This is our clear winner, and it's no surprise given the increasing demand for data-heavy plans.\n",
      "2. **Data Pack 1GB** and **Unlimited Calls** are tied for second place, with **2 sales each**. This suggests that our customers are also interested in smaller data packs and unlimited call plans, which could be an opportunity for us to explore further.\n",
      "\n",
      "It's interesting to see that data packs are dominating our top sales, which might indicate a shift in customer behavior towards more data-centric plans. What would you like to know next?\"\n",
      "================================================================================\n",
      "\n",
      "Question: Now other than those top 3 products which you gave, give me top 2 products from the rest\n",
      "--------------------------------------------------\n",
      "MSISDNs being used: ['9123456789', '9087654321', '9555555555', '9444444444']\n",
      "Generated SQL Query: Here is the SQL query to answer the latest user question:\n",
      "SELECT \n",
      "  p.product_name, \n",
      "  COUNT(cp.product_id) AS sales_count\n",
      "FROM \n",
      "  customer_purchases cp\n",
      "  INNER JOIN products p ON cp.product_id = p.product_id\n",
      "WHERE \n",
      "  cp.msisdn IN ('9123456789', '9087654321', '9555555555', '9444444444')\n",
      "  AND p.product_name NOT IN (\n",
      "    'Data Pack 3GB', \n",
      "    'Data Pack 1GB', \n",
      "    'Unlimited Calls'\n",
      "  )\n",
      "GROUP BY \n",
      "  p.product_name\n",
      "ORDER BY \n",
      "  sales_count DESC\n",
      "LIMIT 2;\n",
      "This query joins the `customer_purchases` and `products` tables, filters out the top 3 products mentioned earlier, and then groups the remaining products by their names and counts the number of sales for each. The results are sorted in descending order by sales count and limited to the top 2 products.\n",
      "Validated SQL Query: SELECT\n",
      "p.product_name,\n",
      "COUNT(cp.product_id) AS sales_count\n",
      "FROM\n",
      "customer_purchases cp\n",
      "INNER JOIN products p ON cp.product_id = p.product_id\n",
      "WHERE\n",
      "cp.msisdn IN ('9123456789', '9087654321', '9555555555', '9444444444')\n",
      "AND p.product_id NOT IN (\n",
      "SELECT product_id\n",
      "FROM products\n",
      "WHERE product_name IN ('Data Pack 3GB', 'Data Pack 1GB', 'Unlimited Calls')\n",
      ")\n",
      "GROUP BY\n",
      "p.product_name\n",
      "ORDER BY\n",
      "sales_count DESC\n",
      "LIMIT 2;\n",
      "Executing SQL Query: SELECT\n",
      "p.product_name,\n",
      "COUNT(cp.product_id) AS sales_count\n",
      "FROM\n",
      "customer_purchases cp\n",
      "INNER JOIN products p ON cp.product_id = p.product_id\n",
      "WHERE\n",
      "cp.msisdn IN ('9123456789', '9087654321', '9555555555', '9444444444')\n",
      "AND p.product_id NOT IN (\n",
      "SELECT product_id\n",
      "FROM products\n",
      "WHERE product_name IN ('Data Pack 3GB', 'Data Pack 1GB', 'Unlimited Calls')\n",
      ")\n",
      "GROUP BY\n",
      "p.product_name\n",
      "ORDER BY\n",
      "sales_count DESC\n",
      "LIMIT 2;\n",
      "Execution Result: [('International Roaming', 1), ('Family Pack', 1)]\n",
      "Answer: Here's a conversational response that answers the question, presents the data clearly, and highlights insights:\n",
      "\n",
      "\"Got it! After excluding the top 3 products, the next two most popular products are:\n",
      "\n",
      "**1. International Roaming** with 1 sale\n",
      "**2. Family Pack** also with 1 sale\n",
      "\n",
      "It's interesting to note that these two products are tied in terms of sales, with each having only 1 sale. This could indicate that there's still some potential for growth in these areas, or that they might be niche products that appeal to specific customer segments.\"\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional\n",
    "import pandas as pd                                           \n",
    "from pprint import pprint\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, END ,MessagesState\n",
    "# from langgraph.prebuilt import \n",
    "\n",
    "# Database connection\n",
    "from sqlalchemy import create_engine, inspect, MetaData, text\n",
    "\n",
    "# Set Groq API key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"\"  # Replace with actual key\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatGroq(model=\"llama3-70b-8192\", temperature=0)\n",
    "\n",
    "# Set up database connection\n",
    "db_uri = \"mysql+pymysql://root:somia@localhost:3306/customer_products\"\n",
    "engine = create_engine(db_uri)\n",
    "db = SQLDatabase.from_uri(db_uri)\n",
    "\n",
    "def read_msisdns_from_file(file_path: str) -> List[str]:\n",
    "    \"\"\"Read MSISDNs from a file, ignoring empty lines and invalid entries.\"\"\"\n",
    "    msisdns = []\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                if line and line.isdigit():\n",
    "                    msisdns.append(line)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading MSISDNs from file: {e}\")\n",
    "    return msisdns\n",
    "\n",
    "msisdn_file_path = \"C:/Users/somia.kumari/Desktop/msisdn.txt\"\n",
    "msisdns = read_msisdns_from_file(msisdn_file_path)\n",
    "print(f\"MSISDNs read from file: {msisdns}\")\n",
    "\n",
    "# Extend MessagesState with additional fields\n",
    "class ExtendedState(MessagesState):\n",
    "    available_tables: Optional[List[str]] = Field(default=None, description=\"List of available tables in the database\")\n",
    "    relevant_tables: Optional[List[str]] = Field(default=None, description=\"List of tables relevant to the query\")\n",
    "    table_schemas: Optional[Dict[str, str]] = Field(default=None, description=\"DDL definitions of relevant tables\")\n",
    "    generated_sql: Optional[str] = Field(default=None, description=\"SQL query generated from the user question\")\n",
    "    execution_result: Optional[Any] = Field(default=None, description=\"Result of executing the SQL query\")\n",
    "    execution_error: Optional[str] = Field(default=None, description=\"Error message if SQL execution failed\")\n",
    "    corrected_sql: Optional[str] = Field(default=None, description=\"Corrected SQL query if original query failed\")\n",
    "    msisdns: Optional[List[str]] = Field(default=None, description=\"List of MSISDNs to filter the query\")\n",
    "\n",
    "# Step 1: Fetch available tables\n",
    "def fetch_available_tables(state: ExtendedState) -> ExtendedState:\n",
    "    inspector = inspect(engine)\n",
    "    available_tables = inspector.get_table_names()\n",
    "    return {\"available_tables\": available_tables}\n",
    "\n",
    "# Step 2: Determine relevant tables\n",
    "def determine_relevant_tables(state: ExtendedState) -> ExtendedState:\n",
    "    latest_query = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
    "    available_tables = state[\"available_tables\"]\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are an expert SQL database analyst. Given the user's question and the list of available tables,\n",
    "    determine which tables are most likely needed to answer the question.\n",
    "    \n",
    "    User question: {query}\n",
    "    \n",
    "    Available tables: {available_tables}\n",
    "    \n",
    "    Return only a comma-separated list of the relevant table names, nothing else.\n",
    "    \"\"\")\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    tables_string = chain.invoke({\n",
    "        \"query\": latest_query,\n",
    "        \"available_tables\": \", \".join(available_tables)\n",
    "    })\n",
    "    \n",
    "    table_pattern = re.compile(r'[\\w_]+')\n",
    "    potential_tables = table_pattern.findall(tables_string)\n",
    "    relevant_tables = [table for table in potential_tables if table in available_tables]\n",
    "    \n",
    "    if not relevant_tables and available_tables:\n",
    "        relevant_tables = available_tables\n",
    "    \n",
    "    return {\"relevant_tables\": relevant_tables}\n",
    "\n",
    "# Step 3: Retrieve table DDL\n",
    "def retrieve_table_schemas(state: ExtendedState) -> ExtendedState:\n",
    "    relevant_tables = state[\"relevant_tables\"]\n",
    "    table_schemas = {}\n",
    "    \n",
    "    for table in relevant_tables:\n",
    "        try:\n",
    "            with engine.connect() as connection:\n",
    "                inspector = inspect(engine)\n",
    "                columns = inspector.get_columns(table)\n",
    "                column_details = []\n",
    "                \n",
    "                for column in columns:\n",
    "                    col_type = str(column['type'])\n",
    "                    nullable = \"NULL\" if column.get('nullable', True) else \"NOT NULL\"\n",
    "                    default = f\"DEFAULT {column.get('default')}\" if column.get('default') is not None else \"\"\n",
    "                    column_details.append(f\"{column['name']} {col_type} {nullable} {default}\".strip())\n",
    "                \n",
    "                pk_info = inspector.get_pk_constraint(table)\n",
    "                if pk_info and pk_info.get('constrained_columns'):\n",
    "                    pk_cols = \", \".join(pk_info['constrained_columns'])\n",
    "                    column_details.append(f\"PRIMARY KEY ({pk_cols})\")\n",
    "                \n",
    "                fk_info = inspector.get_foreign_keys(table)\n",
    "                for fk in fk_info:\n",
    "                    src_cols = \", \".join(fk['constrained_columns'])\n",
    "                    ref_table = fk['referred_table']\n",
    "                    ref_cols = \", \".join(fk['referred_columns'])\n",
    "                    column_details.append(f\"FOREIGN KEY ({src_cols}) REFERENCES {ref_table}({ref_cols})\")\n",
    "                \n",
    "                create_stmt = f\"CREATE TABLE {table} (\\n  \" + \",\\n  \".join(column_details) + \"\\n);\"\n",
    "                table_schemas[table] = create_stmt\n",
    "                \n",
    "                sample_data_query = f\"SELECT * FROM {table} LIMIT 5\"\n",
    "                sample_df = pd.read_sql(sample_data_query, connection)\n",
    "                if not sample_df.empty:\n",
    "                    sample_str = f\"\\n\\n-- Sample data from {table}:\\n\"\n",
    "                    sample_str += sample_df.to_string(index=False)\n",
    "                    table_schemas[table] += sample_str\n",
    "                    \n",
    "        except Exception as e:\n",
    "            table_schemas[table] = f\"Error retrieving schema: {str(e)}\"\n",
    "    \n",
    "    return {\"table_schemas\": table_schemas}\n",
    "\n",
    "# Step 4: Generate SQL query with conversation history\n",
    "def generate_sql_query(state: ExtendedState) -> ExtendedState:\n",
    "    latest_query = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
    "    table_schemas = state[\"table_schemas\"]\n",
    "    msisdns = state[\"msisdns\"]\n",
    "    \n",
    "    print(f\"MSISDNs being used: {msisdns}\")\n",
    "    print(\"Current state before generating SQL:\", state)  # Added print statement\n",
    "    \n",
    "    if msisdns is None:\n",
    "        msisdns = []\n",
    "    msisdns_str = \", \".join([f\"'{msisdn}'\" for msisdn in msisdns])\n",
    "    \n",
    "    conversation_history = \"\\n\".join([f\"{m.type}: {m.content}\" for m in state[\"messages\"]])\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are an expert SQL developer specializing in MySQL syntax. Generate a SQL query to answer this question based on the conversation history:\n",
    "    \n",
    "    Conversation history:\n",
    "    {conversation_history}\n",
    "    \n",
    "    Latest user question: {query}\n",
    "    \n",
    "    Relevant database table definitions:\n",
    "    {table_schemas}\n",
    "    \n",
    "    Filter the results to only include rows where the MSISDN is in: {msisdns_str}\n",
    "    \n",
    "    Guidelines:\n",
    "    1. Use table joins when needed (prefer INNER JOIN)\n",
    "    2. Use appropriate WHERE clauses\n",
    "    3. Include ORDER BY for sorting\n",
    "    4. Add LIMIT clauses for \"top N\" results\n",
    "    5. Use GROUP BY with aggregates when appropriate\n",
    "    6. Fully qualify column references (table.column)\n",
    "    7. Consider previous queries/results to interpret phrases like \"other than those\" or \"the rest\"\n",
    "    \n",
    "    Return only the SQL query.\n",
    "    \"\"\")\n",
    "    \n",
    "    schemas_text = \"\\n\\n\".join([f\"-- Table: {t}\\n{schema}\" for t, schema in table_schemas.items()])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    sql_query = chain.invoke({\n",
    "        \"query\": latest_query,\n",
    "        \"conversation_history\": conversation_history,\n",
    "        \"table_schemas\": schemas_text,\n",
    "        \"msisdns_str\": msisdns_str\n",
    "    })\n",
    "    \n",
    "    sql_query = re.sub(r'```sql\\s*|\\s*```', '', sql_query).strip()\n",
    "    print(f\"Generated SQL Query: {sql_query}\")\n",
    "    \n",
    "    return {\"generated_sql\": sql_query}\n",
    "\n",
    "# Step 5: Validate and optimize SQL\n",
    "def validate_sql(state: ExtendedState) -> ExtendedState:\n",
    "    latest_query = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
    "    sql_query = state[\"generated_sql\"]\n",
    "    table_schemas = state[\"table_schemas\"]\n",
    "    msisdns = state[\"msisdns\"]\n",
    "    \n",
    "    if msisdns is None:\n",
    "        msisdns = []\n",
    "    msisdns_str = \", \".join([f\"'{msisdn}'\" for msisdn in msisdns])\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are an expert SQL reviewer. Review this SQL query:\n",
    "    \n",
    "    User question: {query}\n",
    "    Relevant Tables Schemas:\n",
    "    {table_schemas}\n",
    "    \n",
    "    Generated SQL Query: \n",
    "    {sql_query}\n",
    "    \n",
    "    MSISDN filter list: {msisdns_str}\n",
    "    \n",
    "    Check for:\n",
    "    1. Syntax errors\n",
    "    2. Missing JOIN conditions\n",
    "    3. Inefficient patterns\n",
    "    4. Logic errors\n",
    "    5. Proper aggregation\n",
    "    6. MSISDN filter preservation\n",
    "    \n",
    "    Return only the corrected SQL query with no additional explanatory text or comments.\n",
    "    \"\"\")\n",
    "    \n",
    "    schemas_text = \"\\n\\n\".join([f\"-- Table: {t}\\n{schema}\" for t, schema in table_schemas.items()])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    validated_sql = chain.invoke({\n",
    "        \"query\": latest_query,\n",
    "        \"sql_query\": sql_query,\n",
    "        \"table_schemas\": schemas_text,\n",
    "        \"msisdns_str\": msisdns_str\n",
    "    })\n",
    "    \n",
    "    validated_sql = re.sub(r'```sql\\s*|\\s*```', '', validated_sql).strip()\n",
    "    validated_sql_lines = [line.strip() for line in validated_sql.split('\\n') if line.strip() and not line.strip().startswith(('Here', 'After', '*', '1.', '2.', '3.', '4.', '5.', '6.'))]\n",
    "    validated_sql = '\\n'.join(validated_sql_lines)\n",
    "    \n",
    "    print(f\"Validated SQL Query: {validated_sql}\")\n",
    "    \n",
    "    return {\"generated_sql\": validated_sql} if validated_sql != sql_query else {}\n",
    "\n",
    "# Step 6: Execute SQL query\n",
    "def execute_sql_query(state: ExtendedState) -> ExtendedState:\n",
    "    sql_query = state[\"generated_sql\"]\n",
    "    print(f\"Executing SQL Query: {sql_query}\")\n",
    "    \n",
    "    try:\n",
    "        result = db.run(sql_query)\n",
    "        print(f\"Execution Result: {result}\")\n",
    "        if not result or result.strip() == \"\":\n",
    "            result = \"Query executed successfully, but returned no results.\"\n",
    "        return {\"execution_result\": result, \"execution_error\": None}\n",
    "    except Exception as e:\n",
    "        error_message = str(e)\n",
    "        print(f\"Execution Error: {error_message}\")\n",
    "        return {\"execution_result\": None, \"execution_error\": error_message}\n",
    "\n",
    "# Step 7: Correct SQL on error\n",
    "def correct_sql_on_error(state: ExtendedState) -> ExtendedState:\n",
    "    if not state[\"execution_error\"]:\n",
    "        return {}\n",
    "    \n",
    "    latest_query = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
    "    error_message = state[\"execution_error\"]\n",
    "    original_sql = state[\"generated_sql\"]\n",
    "    table_schemas = state[\"table_schemas\"]\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are an expert SQL debugger. Fix this failed SQL query:\n",
    "    \n",
    "    User question: {query}\n",
    "    Failed SQL query: {original_sql}\n",
    "    Error: {error_message}\n",
    "    Schema: {table_schemas}\n",
    "    \n",
    "    Return only the corrected SQL query with no additional explanatory text or comments.\n",
    "    \"\"\")\n",
    "    \n",
    "    schemas_text = \"\\n\\n\".join([f\"-- Table: {t}\\n{schema}\" for t, schema in table_schemas.items()])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    corrected_sql = chain.invoke({\n",
    "        \"query\": latest_query,\n",
    "        \"original_sql\": original_sql,\n",
    "        \"error_message\": error_message,\n",
    "        \"table_schemas\": schemas_text\n",
    "    })\n",
    "    \n",
    "    corrected_sql = re.sub(r'```sql\\s*|\\s*```', '', corrected_sql).strip()\n",
    "    corrected_sql_lines = [line.strip() for line in corrected_sql.split('\\n') if line.strip() and not line.strip().startswith(('Here', 'After', '*', '1.', '2.', '3.', '4.', '5.', '6.'))]\n",
    "    corrected_sql = '\\n'.join(corrected_sql_lines)\n",
    "    \n",
    "    print(f\"Corrected SQL Query: {corrected_sql}\")\n",
    "    \n",
    "    try:\n",
    "        result = db.run(corrected_sql)\n",
    "        if not result or result.strip() == \"\":\n",
    "            result = \"Query executed successfully after correction, but returned no results.\"\n",
    "        return {\"execution_result\": result, \"execution_error\": None, \"corrected_sql\": corrected_sql}\n",
    "    except Exception as e:\n",
    "        secondary_error = str(e)\n",
    "        return {\n",
    "            \"execution_error\": f\"Original error: {state['execution_error']}\\nCorrection failed: {secondary_error}\",\n",
    "            \"corrected_sql\": corrected_sql\n",
    "        }\n",
    "\n",
    "# Step 8: Formulate response\n",
    "def formulate_response(state: ExtendedState) -> ExtendedState:\n",
    "    latest_query = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
    "    # Use .get() to safely handle cases where corrected_sql might not exist\n",
    "    sql_query = state.get(\"corrected_sql\", state[\"generated_sql\"])\n",
    "    result = state[\"execution_result\"]\n",
    "    error = state[\"execution_error\"]\n",
    "    \n",
    "    if error:\n",
    "        prompt = PromptTemplate.from_template(\"\"\"\n",
    "        The query failed with errors:\n",
    "        \n",
    "        User question: {query}\n",
    "        SQL attempted: {sql_query}\n",
    "        Error: {error}\n",
    "        \n",
    "        Provide a response that:\n",
    "        1. Acknowledges the issue\n",
    "        2. Explains simply what might be wrong\n",
    "        3. Suggests rephrasing\n",
    "        \"\"\")\n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "        response = chain.invoke({\"query\": latest_query, \"sql_query\": sql_query, \"error\": error})\n",
    "    else:\n",
    "        prompt = PromptTemplate.from_template(\"\"\"\n",
    "        Format these SQL results into a clear answer:\n",
    "        \n",
    "        User question: {query}\n",
    "        Results: {result}\n",
    "        \n",
    "        Provide a conversational response that:\n",
    "        1. Answers the question\n",
    "        2. Presents data clearly\n",
    "        3. Highlights insights\n",
    "        \"\"\")\n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "        response = chain.invoke({\"query\": latest_query, \"result\": result})\n",
    "    \n",
    "    return {\"messages\": state[\"messages\"] + [AIMessage(content=response)]}\n",
    "\n",
    "# Define conditional edges\n",
    "def should_correct_sql(state):\n",
    "    return \"correct_sql\" if state[\"execution_error\"] else \"formulate_response\"\n",
    "\n",
    "# Build the LangGraph\n",
    "def build_sql_agent_graph():\n",
    "    workflow = StateGraph(ExtendedState)\n",
    "    \n",
    "    workflow.add_node(\"fetch_tables\", fetch_available_tables)\n",
    "    workflow.add_node(\"determine_tables\", determine_relevant_tables)\n",
    "    workflow.add_node(\"retrieve_schemas\", retrieve_table_schemas)\n",
    "    workflow.add_node(\"generate_sql\", generate_sql_query)\n",
    "    workflow.add_node(\"validate_sql\", validate_sql)\n",
    "    workflow.add_node(\"execute_sql\", execute_sql_query)\n",
    "    workflow.add_node(\"correct_sql\", correct_sql_on_error)\n",
    "    workflow.add_node(\"formulate_response\", formulate_response)\n",
    "    \n",
    "    workflow.add_edge(\"fetch_tables\", \"determine_tables\")\n",
    "    workflow.add_edge(\"determine_tables\", \"retrieve_schemas\")\n",
    "    workflow.add_edge(\"retrieve_schemas\", \"generate_sql\")\n",
    "    workflow.add_edge(\"generate_sql\", \"validate_sql\")\n",
    "    workflow.add_edge(\"validate_sql\", \"execute_sql\")\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"execute_sql\",\n",
    "        should_correct_sql,\n",
    "        {\"correct_sql\": \"correct_sql\", \"formulate_response\": \"formulate_response\"}\n",
    "    )\n",
    "    \n",
    "    workflow.add_edge(\"correct_sql\", \"formulate_response\")\n",
    "    workflow.add_edge(\"formulate_response\", END)\n",
    "    \n",
    "    workflow.set_entry_point(\"fetch_tables\")\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Create the agent\n",
    "sql_agent = build_sql_agent_graph()\n",
    "\n",
    "def query_sql_agent(question: str, msisdn_file_path: str, previous_state: Optional[ExtendedState] = None) -> tuple[str, ExtendedState]:\n",
    "    msisdns = read_msisdns_from_file(msisdn_file_path)\n",
    "    print(f\"Previous state messages: {previous_state['messages'] if previous_state else 'None'}\")\n",
    "    \n",
    "    if previous_state and \"messages\" in previous_state:\n",
    "        initial_state = ExtendedState(messages=previous_state[\"messages\"] + [HumanMessage(content=question)], msisdns=msisdns)\n",
    "    else:\n",
    "        initial_state = ExtendedState(messages=[HumanMessage(content=question)], msisdns=msisdns)\n",
    "    \n",
    "    result = sql_agent.invoke(initial_state)\n",
    "    \n",
    "    final_response = next((m.content for m in reversed(result[\"messages\"]) if isinstance(m, AIMessage)), \"No response found\")\n",
    "    \n",
    "    return final_response, result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_questions = [\n",
    "       \"What are the top 3 products by sales?\",\n",
    "       \"tell me the top 2 from the remaining.\"\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    previous_state = None\n",
    "    for question in sample_questions:\n",
    "        print(f\"\\nQuestion: {question}\")\n",
    "        print(\"-\" * 50)\n",
    "        answer, previous_state = query_sql_agent(question, msisdn_file_path, previous_state)\n",
    "        print(f\"Answer: {answer}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d20b111-cd13-415b-b1c0-1d4092530d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display  # Fixed import for Image\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "# Display the workflow graph\n",
    "display(\n",
    "    Image(\n",
    "        sql_agent.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
