{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0f7bee3-a12d-4367-a9e3-03c3a0e83d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Optional, Union, Literal, Dict, Any\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c41b0e-a8a0-4181-86db-8530e6cf15be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "os.environ[\"GROQ_API_KEY\"] = \"\"\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Create a debug wrapper for LLM\n",
    "def debug_llm_invoke(messages, **kwargs):\n",
    "    print(\"DEBUG - LLM Input Messages:\")\n",
    "    for i, msg in enumerate(messages):\n",
    "        print(f\"Message {i} ({msg.type}):\")\n",
    "        print(f\"{msg.content[:200]}...\" if len(msg.content) > 200 else msg.content)\n",
    "    \n",
    "    result = llm.invoke(messages, **kwargs)\n",
    "    \n",
    "    print(\"\\nDEBUG - LLM Response:\")\n",
    "    print(f\"{result.content[:200]}...\" if len(result.content) > 200 else result.content)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4a0b80-db2a-44e2-86c6-b36c9b67fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ValidationResult(BaseModel):\n",
    "#     \"\"\"Structure for response validation results\"\"\"\n",
    "#     valid: bool\n",
    "#     processed_value: Optional[str]\n",
    "#     reasoning: str\n",
    "#     follow_up_question: Optional[str] = None\n",
    "\n",
    "\n",
    "class ValidationResult(BaseModel):\n",
    "    \"\"\"Structure for response validation results\"\"\"\n",
    "    valid: bool\n",
    "    processed_value: Optional[Dict[str, Optional[str]]] = None  # Changed to dictionary\n",
    "    reasoning: str\n",
    "    follow_up_question: Optional[str] = None\n",
    "   \n",
    "\n",
    "\n",
    "class ManagerDecision(BaseModel):\n",
    "    \"\"\"Structure for LLM's decision about next steps\"\"\"\n",
    "    action: Literal[\"planning\", \"collection\", \"end\", \"general_conversation\"]\n",
    "    status: Literal[\"pending\", \"in_progress\", \"completed\"]\n",
    "    next_step: Optional[str] = None\n",
    "    next_question: Optional[str] = None\n",
    "    reasoning: str\n",
    "    validation_feedback: Optional[str] = None\n",
    "\n",
    "# State Management Classes\n",
    "class CampaignStep(BaseModel):\n",
    "    \"\"\"Represents a single step in the campaign creation process\"\"\"\n",
    "    task: str\n",
    "    required_info: List[str]\n",
    "    collected_info: Dict[str, Any] = Field(default_factory=dict)\n",
    "    validation_rules: Dict[str, str]\n",
    "    questions: Dict[str, str]  # Maps required_info to specific questions\n",
    "    last_question: Optional[str] = None  # Tracks the last question asked\n",
    "    expected_input: Optional[str] = None  # Tracks what input we're expecting\n",
    "    status: str = \"pending\"  # pending/in_progress/completed\n",
    "    output: Optional[str] = None\n",
    "\n",
    "class CampaignInfo(BaseModel):\n",
    "    \"\"\"Tracks overall campaign information and progress\"\"\"\n",
    "    steps: Dict[str, CampaignStep]\n",
    "    current_step: str\n",
    "    stage: str = \"planning\"  # planning/collection/validation/complete\n",
    "\n",
    "class TaskState(MessagesState):\n",
    "    \"\"\"Main state management for the workflow\"\"\"\n",
    "    conversation_id: str\n",
    "    action: Optional[str]\n",
    "    campaign_info: Optional[CampaignInfo]\n",
    "    output: str = \"\"\n",
    "    status: str = \"pending\"\n",
    "\n",
    "# Task Identification Model\n",
    "class TaskIdentification(BaseModel):\n",
    "    task_type: Literal[\"general_convo\", \"campaign_convo\", \"other_services\"]\n",
    "    description: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc048d19-183c-4894-a735-28d8a34116a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_identifier(state: TaskState):\n",
    "    \"\"\"Identifies the type of task from user input using only the last 3 messages.\"\"\"\n",
    "    print(\"\\n>>> DEBUGGING TASK_IDENTIFIER NODE <<<\")\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(TaskIdentification)\n",
    "    \n",
    "    # Get the last 3 messages\n",
    "    last_3_messages = state[\"messages\"][-3:] if state[\"messages\"] else []\n",
    "    \n",
    "    # Extract the content of the last 3 messages\n",
    "    last_3_messages_content = [msg.content for msg in last_3_messages]\n",
    "    \n",
    "    # Combine the last 3 messages into a single string\n",
    "    combined_messages = \"\\n\".join(last_3_messages_content)\n",
    "    print(\"Input messages:\", combined_messages)\n",
    "    \n",
    "    # Identify task type using only the last 3 messages\n",
    "    prompt = f\"Identify if this is a campaign-related request or general conversation based on the following messages:\\n{combined_messages}\"\n",
    "    print(f\"Prompt to LLM: {prompt}\")\n",
    "    \n",
    "    result = structured_llm.invoke(prompt)\n",
    "    print(\"Task identification result:\", result)\n",
    "    \n",
    "    output = {\n",
    "        \"action\": result.task_type,\n",
    "        \"output\": f\"Task identified as: {result.task_type}\"\n",
    "    }\n",
    "    print(\"Node output:\", output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e62b9ab0-0aa0-487b-8937-8f1d0501b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def campaign_manager(state: TaskState):\n",
    "    \"\"\"Enhanced campaign manager with debugging\"\"\"\n",
    "    print(\"\\n>>> DEBUGGING CAMPAIGN_MANAGER NODE <<<\")\n",
    "    print(f\"Input state action: {state['action']}\")\n",
    "    print(f\"Input state status: {state.get('status')}\")\n",
    "    \n",
    "    # Existing initial checks remain the same\n",
    "    if state[\"action\"] == \"general_convo\":\n",
    "        print(\"Identified as general conversation, routing accordingly\")\n",
    "        return {\"action\": \"general_convo\"}\n",
    "    \n",
    "    campaign_info = state.get(\"campaign_info\")\n",
    "    print(f\"Campaign info exists: {campaign_info is not None}\")\n",
    "    \n",
    "    if not campaign_info:\n",
    "        print(\"No campaign info, routing to planning\")\n",
    "        return {\n",
    "            \"action\": \"planning\",\n",
    "            \"status\": \"pending\"\n",
    "        }\n",
    "\n",
    "    current_step = campaign_info.steps[campaign_info.current_step]\n",
    "    print(f\"Current step: {campaign_info.current_step}\")\n",
    "    print(f\"Current step status: {current_step.status}\")\n",
    "    \n",
    "    last_message = state[\"messages\"][-1].content if state[\"messages\"] else None\n",
    "    print(f\"Last message: {last_message}\")\n",
    "\n",
    "\n",
    "    # If we're in waiting status, process the user's response\n",
    "    if current_step.status == \"waiting\" and last_message:\n",
    "        print(\"Processing user response for waiting state\")\n",
    "\n",
    "        # Get current missing information\n",
    "        missing_info = [\n",
    "            info for info in current_step.required_info\n",
    "            if info not in current_step.collected_info\n",
    "        ]\n",
    "\n",
    "        print(\"---------\",current_step.collected_info)\n",
    "\n",
    "        print(\"MISIIIIIIING\",missing_info)\n",
    "        \n",
    "        # Create a structured prompt for validation\n",
    "        validation_prompt = f\"\"\"\n",
    "        You are validating a user response for a marketing campaign setup.\n",
    "\n",
    "        \n",
    "\n",
    "        Context:\n",
    "        Extract and validate ONLY FROM THIS RESPONSE: \"{last_message}\"\n",
    "        Already collected: {current_step.collected_info}\n",
    "        Missing fields: {missing_info}\n",
    "        Validation Rules:{json.dumps(current_step.validation_rules, indent=2)}\n",
    "\n",
    "        If the response is invalid, generate a follow-up question that:\n",
    "        1. Acknowledges their response\n",
    "        2. Explains what was missing or incorrect\n",
    "        3. Asks for the information in a clearer way\n",
    "\n",
    "        Return a JSON structure with these exact fields:\n",
    "        {{\n",
    "            \"valid\": boolean,\n",
    "            \"processed_value\": extracted values for ALL fields,\n",
    "            \"reasoning\": string explaining the validation result,\n",
    "            \"follow_up_question\": string if invalid, null if valid\n",
    "        }}\n",
    "        \"\"\"\n",
    "        print(\"Validation prompt:\", validation_prompt[:200] + \"...\")\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "        # Get LLM to validate with structured output\n",
    "        structured_llm = llm.with_structured_output(ValidationResult)\n",
    "        validation_result = structured_llm.invoke(validation_prompt)\n",
    "        print(f\"Validation result: valid={validation_result.valid}, reasoning={validation_result.reasoning[:100]}...\")\n",
    "\n",
    "\n",
    "# For partial validation - when some fields were extracted but others are missing\n",
    "\n",
    "        if validation_result.valid:\n",
    "            print(\"Response validated as valid\")\n",
    "            # Store the processed response\n",
    "            # current_step.collected_info[current_step.last_question] = validation_result.processed_value\n",
    "            current_step.collected_info.update(validation_result.processed_value)\n",
    "            print(f\"Updated collected_info: {current_step.collected_info}\")\n",
    " \n",
    "            # Check if we have all required info for this step\n",
    "            missing_info = [\n",
    "                info for info in current_step.required_info\n",
    "                if info not in current_step.collected_info\n",
    "            ]\n",
    "            print(f\"Missing info for current step: {missing_info}\")\n",
    "\n",
    "            if not missing_info:\n",
    "                print(\"Step completed, looking for next incomplete step\")\n",
    "                # Current step is complete\n",
    "                current_step.status = \"completed\"\n",
    "\n",
    "                # Look for the next incomplete step\n",
    "                next_incomplete_step = None\n",
    "                for step_name, step in campaign_info.steps.items():\n",
    "                    # Skip steps we've already completed and the current step\n",
    "                    if step_name == campaign_info.current_step:\n",
    "                        continue\n",
    "                    if step.status != \"completed\":\n",
    "                        next_incomplete_step = step_name\n",
    "                        break\n",
    "\n",
    "                if next_incomplete_step:\n",
    "                    print(f\"Found next incomplete step: {next_incomplete_step}\")\n",
    "                    # We found another step that needs completion\n",
    "                    campaign_info.current_step = next_incomplete_step\n",
    "                    campaign_info.steps[next_incomplete_step].status = \"in_progress\"\n",
    "\n",
    "                    output = {\n",
    "                        \"action\": \"collection\",\n",
    "                        \"status\": \"in_progress\",\n",
    "                        \"campaign_info\": campaign_info\n",
    "                    }\n",
    "                    print(\"Node output:\", output)\n",
    "                    return output\n",
    "                else:\n",
    "                    print(\"All steps completed, finishing campaign\")\n",
    "                    # All steps are completed - campaign is done\n",
    "                    output = {\n",
    "                        \"action\": \"end\",\n",
    "                        \"status\": \"completed\",\n",
    "                        \"campaign_info\": campaign_info,\n",
    "                        \"output\": \"Great! We've completed all the steps for your campaign setup.\"\n",
    "                    }\n",
    "                    print(\"Node output:\", output)\n",
    "                    return output\n",
    "                \n",
    "            else:\n",
    "                print(\"More questions needed in this step\")\n",
    "                # More questions needed in this step\n",
    "                current_step.status = \"in_progress\"\n",
    "                output = {\n",
    "                    \"action\": \"collection\",\n",
    "                    \"status\": \"in_progress\",\n",
    "                    \"campaign_info\": campaign_info\n",
    "                }\n",
    "                print(\"Node output:\", output)\n",
    "                return output\n",
    "        \n",
    "        else:\n",
    "            print(\"Response validated as invalid, follow-up needed\")\n",
    "            # For invalid response, update status and route to END with follow-up question\n",
    "            current_step.status = \"waiting\"  # Keep waiting since we're asking a follow-up\n",
    "            # Maintain the same question we're trying to answer\n",
    "            messages = state[\"messages\"] + [validation_result.follow_up_question]\n",
    "            # Return the follow-up question and route to END\n",
    "            output = {\n",
    "                \"action\": \"end\",\n",
    "                \"status\": \"waiting\",\n",
    "                \"messages\": messages,\n",
    "                \"campaign_info\": campaign_info,\n",
    "                \"output\": validation_result.follow_up_question\n",
    "            }\n",
    "            # print('--------------------',output)\n",
    "            print(\"Node output action: end, with follow-up question\")\n",
    "            return output\n",
    "    \n",
    "    # Default case\n",
    "    print(\"Continuing with current campaign state without changes\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14519686-7f7a-4a6d-a80c-1d7745748e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def campaign_planner(state: TaskState):\n",
    "    \"\"\"Plans the campaign creation steps and transitions to collection stage\"\"\"\n",
    "    print(\"\\n>>> DEBUGGING CAMPAIGN_PLANNER NODE <<<\")\n",
    "    \n",
    "    # Define the campaign creation steps with comprehensive question sets\n",
    "    campaign_steps = {\n",
    "        \"segment_definition\": CampaignStep(\n",
    "            task=\"Define target segment\",\n",
    "            required_info=[\"segment_condition\"],\n",
    "            validation_rules={\n",
    "                \"segment_condition\": \"Must be a  condition in text \"\n",
    "            },\n",
    "            questions={\n",
    "                \"segment_condition\": \"What conditions should be used to identify the target segment? (eg people who got revenue greater that 100 etc )\"\n",
    "            }\n",
    "        ),\n",
    "        \"action_type\": CampaignStep(\n",
    "            task=\"Define campaign action\",\n",
    "            required_info=[\"action_type\", \"value\", \"duration\"],\n",
    "            validation_rules={\n",
    "                \"action_type\": \"Must be either 'bonus' or 'discount',it might be in sentence\",\n",
    "                \"value\": \"Must contain a number, even if percentages, currency symbols, or names are included (e.g., 10%, $10, 10 dollars, 10 rupees)\",\n",
    "                \"duration\": \"Must be a valid duration in days\"\n",
    "            },\n",
    "           questions={\n",
    "            \"combined\": \"What type of reward (bonus/discount), value, and duration would you like to offer? \"\n",
    "           }\n",
    "        ),\n",
    "        \"channel_strategy\": CampaignStep(\n",
    "            task=\"Define communication channels\",\n",
    "            required_info=[\"channels\", \"message_template\", \"frequency\"],\n",
    "            validation_rules={\n",
    "                \"channels\": \"Must include word like: SMS, email, push, telegram , it might be in sentence\",\n",
    "                \"message_template\": \"can be any message template\",\n",
    "                \"frequency\": \"Must be one of: immediate, daily, weekly\"\n",
    "            },\n",
    "            questions={\n",
    "                \"channels\": \"Which communication channels should be used? (SMS/email/push/telegram, can select multiple)\",\n",
    "                \"message_template\": \"What message should be sent to users?\",\n",
    "                \"frequency\": \"How often should messages be sent? (immediate/daily/weekly)\"\n",
    "            }\n",
    "        ),\n",
    "        \"scheduling\": CampaignStep(\n",
    "            task=\"Define campaign schedule\",\n",
    "            required_info=[\"start_date\", \"end_date\", \"time_zone\"],\n",
    "            validation_rules={\n",
    "                \"start_date\": \"can be in any date format\",\n",
    "                \"end_date\": \"can be in any date format and can be in different date format than start date\",\n",
    "                \"time_zone\": \"Must be a valid timezone identifier (e.g., UTC, America/New_York)\"\n",
    "            },\n",
    "            questions={\n",
    "                \"start_date\": \"When should the campaign start? \",\n",
    "                \"end_date\": \"When should the campaign end? \",\n",
    "                \"time_zone\": \"What timezone should be used for the campaign?\"\n",
    "            }\n",
    "        )\n",
    "    }\n",
    "\n",
    "    print(f\"Setting up campaign with {len(campaign_steps)} steps\")\n",
    "    \n",
    "    # Create campaign info with initial step\n",
    "    campaign_info = CampaignInfo(\n",
    "        steps=campaign_steps,\n",
    "        current_step=\"segment_definition\",\n",
    "        stage=\"collection\"  # Set initial stage to collection\n",
    "    )\n",
    "    \n",
    "    initial_step = campaign_info.steps[\"segment_definition\"]\n",
    "    print(f\"Initial step: {initial_step.task}\")\n",
    "    print(f\"Initial step required info: {initial_step.required_info}\")\n",
    "\n",
    "    output = {\n",
    "        \"campaign_info\": campaign_info,\n",
    "        \"action\": \"collection\",\n",
    "        \"status\": \"in_progress\",\n",
    "        \"output\": \"Campaign plan created. Let's start by defining the target segment.\"\n",
    "    }\n",
    "    print(\"Node output:\", output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dca9999-b2d5-4a45-9f47-720144444452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_task_executor(state: TaskState):\n",
    "    \"\"\"Collects information for the current campaign step by generating natural questions\"\"\"\n",
    "    print(\"\\n>>> DEBUGGING SINGLE_TASK_EXECUTOR NODE <<<\")\n",
    "    \n",
    "    campaign_info = state[\"campaign_info\"]\n",
    "    current_step = campaign_info.steps[campaign_info.current_step]\n",
    "    print(f\"Current step: {current_step.task}\")\n",
    "    print(f\"Required info: {current_step.required_info}\")\n",
    "    print(f\"Collected info: {current_step.collected_info}\")\n",
    "\n",
    "    # Get both collected and missing information\n",
    "    missing_info = [\n",
    "        info for info in current_step.required_info\n",
    "        if info not in current_step.collected_info\n",
    "    ]\n",
    "    print(f\"Missing info: {missing_info}\")\n",
    "\n",
    "    # Create a context section showing what we already know\n",
    "    collected_context = \"\"\n",
    "    if current_step.collected_info:\n",
    "        collected_context = \"Information we've already collected:\\n\"\n",
    "        for info_key, info_value in current_step.collected_info.items():\n",
    "            collected_context += f\"- {info_key}: {info_value}\\n\"\n",
    "    print(f\"Collected context: {collected_context}\")\n",
    "\n",
    "    # Create a section for what we still need to know\n",
    "    missing_context = \"Information we still need:\\n\"\n",
    "    for info in missing_info:\n",
    "        missing_context += f\"- {info}: {current_step.questions.get(info, 'No predefined question')}\\n\"\n",
    "    print(f\"Missing context: {missing_context}\")\n",
    "\n",
    "    # Generate combined question if multiple fields are needed\n",
    "    if len(missing_info) > 1:\n",
    "        prompt = f\"\"\"\n",
    "        Generate a SINGLE question that naturally asks for all these at once:\n",
    "        {', '.join([current_step.questions.get(info, info) for info in missing_info])}\n",
    "\n",
    "        Include an example and be conversational. Ask for ALL needed information.\n",
    "        \"\"\"\n",
    "    else:\n",
    "        # Enhanced prompt that includes full context\n",
    "        prompt = f\"\"\"\n",
    "        You are a helpful marketing campaign assistant having a conversation with a user.\n",
    "        We are currently working on the step: '{current_step.task}'\n",
    "\n",
    "        CONTEXT OF OUR PROGRESS:\n",
    "        {collected_context if collected_context else \"This is the beginning of this step - no information collected yet.\"}\n",
    "\n",
    "        NEXT INFORMATION NEEDED:\n",
    "        We need to ask about: {missing_info[0]}\n",
    "        Original question format: {current_step.questions.get(missing_info[0], 'No predefined question')}\n",
    "        Validation rule: {current_step.validation_rules.get(missing_info[0], 'No validation rule')}\n",
    "\n",
    "        TASK:\n",
    "        Generate a direct, single-sentence question that:\n",
    "        1. Acknowledges any previously collected information (if any exists)\n",
    "        2. Clearly asks for the specific information needed\n",
    "        3. Includes brief examples if necessary\n",
    "        4. Must be 1-2 lines only, no lengthy explanations\n",
    "     \n",
    "        Keep responses under 2 sentences. Be direct and clear.\n",
    "        \"\"\"\n",
    "    \n",
    "    print(f\"Prompt to LLM: {prompt[:200]}...\")\n",
    "\n",
    "    # Get next unanswered question key\n",
    "    next_info_key = missing_info[0] if missing_info else None\n",
    "    print(f\"Next info key: {next_info_key}\")\n",
    "\n",
    "    if next_info_key:\n",
    "        # Get LLM to formulate the question\n",
    "        response = debug_llm_invoke([SystemMessage(content=prompt)])\n",
    "        formulated_question = response.content\n",
    "        print(f\"Formulated question: {formulated_question}\")\n",
    "\n",
    "        # Update step status and tracking\n",
    "        current_step.last_question = next_info_key\n",
    "        current_step.expected_input = next_info_key\n",
    "        current_step.status = \"waiting\"\n",
    "        messages = state[\"messages\"] + [response]\n",
    "\n",
    "        output = {\n",
    "            \"campaign_info\": campaign_info,\n",
    "            \"output\": formulated_question,\n",
    "            \"status\": \"waiting\",\n",
    "            \"messages\": messages\n",
    "        }\n",
    "        print(\"Node output status: waiting with formulated question\")\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0adc750-7f56-43e5-bef5-8020a8985260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_conversation_agent(state: TaskState):\n",
    "    \"\"\"Handles general conversation with the user\"\"\"\n",
    "    print(\"\\n>>> DEBUGGING GENERAL_CONVERSATION_AGENT NODE <<<\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    print(f\"Number of input messages: {len(messages)}\")\n",
    "    if messages:\n",
    "        print(f\"Last message: {messages[-1].content[:100]}...\")\n",
    "    \n",
    "    system_prompt = \"\"\"You are a helpful assistant engaging in general conversation.\n",
    "    Maintain a friendly and informative tone while providing relevant responses.\"\"\"\n",
    "    print(f\"System prompt: {system_prompt}\")\n",
    "\n",
    "    response = debug_llm_invoke([SystemMessage(content=system_prompt)] + messages)\n",
    "    print(f\"Generated response: {response.content[:100]}...\")\n",
    "\n",
    "    output = {\n",
    "        \"output\": response.content,\n",
    "        \"messages\": messages + [response]\n",
    "    }\n",
    "    print(\"Node output: general conversation response generated\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c47ad13d-175d-440a-81a5-78dc1bb98654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_based_on_action(state: TaskState):\n",
    "    \"\"\"Routes to appropriate node based on action and status\"\"\"\n",
    "    print(\"\\n>>> DEBUGGING ROUTER <<<\")\n",
    "    print(f\"Input state action: {state['action']}\")\n",
    "    print(f\"Input state status: {state.get('status')}\")\n",
    "    \n",
    "    if state[\"action\"] == \"end\":\n",
    "        print(\"Routing to END\")\n",
    "        return END\n",
    "    elif state[\"action\"] == \"planning\":\n",
    "        print(\"Routing to campaign_planner\")\n",
    "        return \"campaign_planner\"\n",
    "    elif state[\"action\"] == \"collection\":\n",
    "        print(\"Routing to single_task_executor\")\n",
    "        return \"single_task_executor\"\n",
    "    elif state[\"action\"] == \"general_convo\":\n",
    "        print(\"Routing to general_conversation_agent\")\n",
    "        return \"general_conversation_agent\"\n",
    "    else:\n",
    "        print(\"Default routing to campaign_manager\")\n",
    "        return \"campaign_manager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8001cbe6-5405-4c36-9992-c98fd03e62f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow graph compiled successfully\n"
     ]
    }
   ],
   "source": [
    "# Build workflow graph\n",
    "workflow = StateGraph(TaskState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"task_identifier\", task_identifier)\n",
    "workflow.add_node(\"campaign_manager\", campaign_manager)\n",
    "workflow.add_node(\"campaign_planner\", campaign_planner)\n",
    "workflow.add_node(\"single_task_executor\", single_task_executor)\n",
    "workflow.add_node(\"general_conversation_agent\", general_conversation_agent)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"task_identifier\")\n",
    "workflow.add_edge(\"task_identifier\", \"campaign_manager\")\n",
    "\n",
    "# Add conditional edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"campaign_manager\",\n",
    "    route_based_on_action,\n",
    "    {\n",
    "        \"campaign_planner\": \"campaign_planner\",\n",
    "        \"single_task_executor\": \"single_task_executor\",\n",
    "        \"general_conversation_agent\": \"general_conversation_agent\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"campaign_planner\", \"campaign_manager\")\n",
    "workflow.add_edge(\"single_task_executor\", END)\n",
    "workflow.add_edge(\"general_conversation_agent\", END)\n",
    "\n",
    "# Compile graph with memory\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "print(\"Workflow graph compiled successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eddb2b52-cfb5-4bf7-a67c-e559e67bbf2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TESTING COMPLETE CAMPAIGN FLOW =====\n",
      "\n",
      "STEP 1: INITIALIZING CAMPAIGN\n",
      "\n",
      ">>> DEBUGGING TASK_IDENTIFIER NODE <<<\n",
      "Input messages: 10 days\n",
      "You mentioned '10 days', which is a valid duration. However, could you please clarify what type of action you'd like to take, such as a 'bonus' or 'discount', and what value this action will have?\n",
      "I want to create a campaign\n",
      "Prompt to LLM: Identify if this is a campaign-related request or general conversation based on the following messages:\n",
      "10 days\n",
      "You mentioned '10 days', which is a valid duration. However, could you please clarify what type of action you'd like to take, such as a 'bonus' or 'discount', and what value this action will have?\n",
      "I want to create a campaign\n",
      "Task identification result: task_type='campaign_convo' description='The user wants to create a campaign'\n",
      "Node output: {'action': 'campaign_convo', 'output': 'Task identified as: campaign_convo'}\n",
      "\n",
      ">>> DEBUGGING CAMPAIGN_MANAGER NODE <<<\n",
      "Input state action: campaign_convo\n",
      "Input state status: pending\n",
      "Campaign info exists: False\n",
      "No campaign info, routing to planning\n",
      "\n",
      ">>> DEBUGGING ROUTER <<<\n",
      "Input state action: planning\n",
      "Input state status: pending\n",
      "Routing to campaign_planner\n",
      "\n",
      ">>> DEBUGGING CAMPAIGN_PLANNER NODE <<<\n",
      "Setting up campaign with 4 steps\n",
      "Initial step: Define target segment\n",
      "Initial step required info: ['segment_condition']\n",
      "Node output: {'campaign_info': CampaignInfo(steps={'segment_definition': CampaignStep(task='Define target segment', required_info=['segment_condition'], collected_info={}, validation_rules={'segment_condition': 'Must be a  condition in text '}, questions={'segment_condition': 'What conditions should be used to identify the target segment? (eg people who got revenue greater that 100 etc )'}, last_question=None, expected_input=None, status='pending', output=None), 'action_type': CampaignStep(task='Define campaign action', required_info=['action_type', 'value', 'duration'], collected_info={}, validation_rules={'action_type': \"Must be either 'bonus' or 'discount',it might be in sentence\", 'value': 'Must contain a number, even if percentages, currency symbols, or names are included (e.g., 10%, $10, 10 dollars, 10 rupees)', 'duration': 'Must be a valid duration in days'}, questions={'combined': 'What type of reward (bonus/discount), value, and duration would you like to offer? '}, last_question=None, expected_input=None, status='pending', output=None), 'channel_strategy': CampaignStep(task='Define communication channels', required_info=['channels', 'message_template', 'frequency'], collected_info={}, validation_rules={'channels': 'Must include word like: SMS, email, push, telegram , it might be in sentence', 'message_template': 'can be any message template', 'frequency': 'Must be one of: immediate, daily, weekly'}, questions={'channels': 'Which communication channels should be used? (SMS/email/push/telegram, can select multiple)', 'message_template': 'What message should be sent to users?', 'frequency': 'How often should messages be sent? (immediate/daily/weekly)'}, last_question=None, expected_input=None, status='pending', output=None), 'scheduling': CampaignStep(task='Define campaign schedule', required_info=['start_date', 'end_date', 'time_zone'], collected_info={}, validation_rules={'start_date': 'can be in any date format', 'end_date': 'can be in any date format and can be in different date format than start date', 'time_zone': 'Must be a valid timezone identifier (e.g., UTC, America/New_York)'}, questions={'start_date': 'When should the campaign start? ', 'end_date': 'When should the campaign end? ', 'time_zone': 'What timezone should be used for the campaign?'}, last_question=None, expected_input=None, status='pending', output=None)}, current_step='segment_definition', stage='collection'), 'action': 'collection', 'status': 'in_progress', 'output': \"Campaign plan created. Let's start by defining the target segment.\"}\n",
      "\n",
      ">>> DEBUGGING CAMPAIGN_MANAGER NODE <<<\n",
      "Input state action: collection\n",
      "Input state status: in_progress\n",
      "Campaign info exists: True\n",
      "Current step: segment_definition\n",
      "Current step status: pending\n",
      "Last message: I want to create a campaign\n",
      "Continuing with current campaign state without changes\n",
      "\n",
      ">>> DEBUGGING ROUTER <<<\n",
      "Input state action: collection\n",
      "Input state status: in_progress\n",
      "Routing to single_task_executor\n",
      "\n",
      ">>> DEBUGGING SINGLE_TASK_EXECUTOR NODE <<<\n",
      "Current step: Define target segment\n",
      "Required info: ['segment_condition']\n",
      "Collected info: {}\n",
      "Missing info: ['segment_condition']\n",
      "Collected context: \n",
      "Missing context: Information we still need:\n",
      "- segment_condition: What conditions should be used to identify the target segment? (eg people who got revenue greater that 100 etc )\n",
      "\n",
      "Prompt to LLM: \n",
      "        You are a helpful marketing campaign assistant having a conversation with a user.\n",
      "        We are currently working on the step: 'Define target segment'\n",
      "\n",
      "        CONTEXT OF OUR PROGRESS:\n",
      "     ...\n",
      "Next info key: segment_condition\n",
      "DEBUG - LLM Input Messages:\n",
      "Message 0 (system):\n",
      "\n",
      "        You are a helpful marketing campaign assistant having a conversation with a user.\n",
      "        We are currently working on the step: 'Define target segment'\n",
      "\n",
      "        CONTEXT OF OUR PROGRESS:\n",
      "     ...\n",
      "\n",
      "DEBUG - LLM Response:\n",
      "Since we're starting from scratch, what conditions should be used to identify the target segment, such as people who have revenue greater than 100 or other specific criteria?\n",
      "Formulated question: Since we're starting from scratch, what conditions should be used to identify the target segment, such as people who have revenue greater than 100 or other specific criteria?\n",
      "Node output status: waiting with formulated question\n",
      "\n",
      "Step 1 Output: Since we're starting from scratch, what conditions should be used to identify the target segment, such as people who have revenue greater than 100 or other specific criteria?\n",
      "\n",
      "STEP 2: DEFINING TARGET SEGMENT\n",
      "\n",
      ">>> DEBUGGING TASK_IDENTIFIER NODE <<<\n",
      "Input messages: I want to create a campaign\n",
      "Since we're starting from scratch, what conditions should be used to identify the target segment, such as people who have revenue greater than 100 or other specific criteria?\n",
      "Target users with revenue greater than $1000 in the last month\n",
      "Prompt to LLM: Identify if this is a campaign-related request or general conversation based on the following messages:\n",
      "I want to create a campaign\n",
      "Since we're starting from scratch, what conditions should be used to identify the target segment, such as people who have revenue greater than 100 or other specific criteria?\n",
      "Target users with revenue greater than $1000 in the last month\n",
      "Task identification result: task_type='campaign_convo' description='Identify target segment conditions for a campaign'\n",
      "Node output: {'action': 'campaign_convo', 'output': 'Task identified as: campaign_convo'}\n",
      "\n",
      ">>> DEBUGGING CAMPAIGN_MANAGER NODE <<<\n",
      "Input state action: campaign_convo\n",
      "Input state status: waiting\n",
      "Campaign info exists: True\n",
      "Current step: segment_definition\n",
      "Current step status: waiting\n",
      "Last message: Target users with revenue greater than $1000 in the last month\n",
      "Processing user response for waiting state\n",
      "--------- {}\n",
      "MISIIIIIIING ['segment_condition']\n",
      "Validation prompt: \n",
      "        You are validating a user response for a marketing campaign setup.\n",
      "\n",
      "        \n",
      "\n",
      "        Context:\n",
      "        Extract and validate ONLY FROM THIS RESPONSE: \"Target users with revenue greater than $1...\n",
      "Validation result: valid=True, reasoning=The response contains a valid segment condition in text....\n",
      "Response validated as valid\n",
      "Updated collected_info: {'segment_condition': 'Target users with revenue greater than $1000 in the last month'}\n",
      "Missing info for current step: []\n",
      "Step completed, looking for next incomplete step\n",
      "Found next incomplete step: action_type\n",
      "Node output: {'action': 'collection', 'status': 'in_progress', 'campaign_info': CampaignInfo(steps={'segment_definition': CampaignStep(task='Define target segment', required_info=['segment_condition'], collected_info={'segment_condition': 'Target users with revenue greater than $1000 in the last month'}, validation_rules={'segment_condition': 'Must be a  condition in text '}, questions={'segment_condition': 'What conditions should be used to identify the target segment? (eg people who got revenue greater that 100 etc )'}, last_question='segment_condition', expected_input='segment_condition', status='completed', output=None), 'action_type': CampaignStep(task='Define campaign action', required_info=['action_type', 'value', 'duration'], collected_info={}, validation_rules={'action_type': \"Must be either 'bonus' or 'discount',it might be in sentence\", 'value': 'Must contain a number, even if percentages, currency symbols, or names are included (e.g., 10%, $10, 10 dollars, 10 rupees)', 'duration': 'Must be a valid duration in days'}, questions={'combined': 'What type of reward (bonus/discount), value, and duration would you like to offer? '}, last_question=None, expected_input=None, status='in_progress', output=None), 'channel_strategy': CampaignStep(task='Define communication channels', required_info=['channels', 'message_template', 'frequency'], collected_info={}, validation_rules={'channels': 'Must include word like: SMS, email, push, telegram , it might be in sentence', 'message_template': 'can be any message template', 'frequency': 'Must be one of: immediate, daily, weekly'}, questions={'channels': 'Which communication channels should be used? (SMS/email/push/telegram, can select multiple)', 'message_template': 'What message should be sent to users?', 'frequency': 'How often should messages be sent? (immediate/daily/weekly)'}, last_question=None, expected_input=None, status='pending', output=None), 'scheduling': CampaignStep(task='Define campaign schedule', required_info=['start_date', 'end_date', 'time_zone'], collected_info={}, validation_rules={'start_date': 'can be in any date format', 'end_date': 'can be in any date format and can be in different date format than start date', 'time_zone': 'Must be a valid timezone identifier (e.g., UTC, America/New_York)'}, questions={'start_date': 'When should the campaign start? ', 'end_date': 'When should the campaign end? ', 'time_zone': 'What timezone should be used for the campaign?'}, last_question=None, expected_input=None, status='pending', output=None)}, current_step='action_type', stage='collection')}\n",
      "\n",
      ">>> DEBUGGING ROUTER <<<\n",
      "Input state action: collection\n",
      "Input state status: in_progress\n",
      "Routing to single_task_executor\n",
      "\n",
      ">>> DEBUGGING SINGLE_TASK_EXECUTOR NODE <<<\n",
      "Current step: Define campaign action\n",
      "Required info: ['action_type', 'value', 'duration']\n",
      "Collected info: {}\n",
      "Missing info: ['action_type', 'value', 'duration']\n",
      "Collected context: \n",
      "Missing context: Information we still need:\n",
      "- action_type: No predefined question\n",
      "- value: No predefined question\n",
      "- duration: No predefined question\n",
      "\n",
      "Prompt to LLM: \n",
      "        Generate a SINGLE question that naturally asks for all these at once:\n",
      "        action_type, value, duration\n",
      "\n",
      "        Include an example and be conversational. Ask for ALL needed information.\n",
      " ...\n",
      "Next info key: action_type\n",
      "DEBUG - LLM Input Messages:\n",
      "Message 0 (system):\n",
      "\n",
      "        Generate a SINGLE question that naturally asks for all these at once:\n",
      "        action_type, value, duration\n",
      "\n",
      "        Include an example and be conversational. Ask for ALL needed information.\n",
      " ...\n",
      "\n",
      "DEBUG - LLM Response:\n",
      "What kind of action are you planning to take (e.g. running, studying, etc.), what's the intensity or value of that action (e.g. how fast, how much), and for how long do you plan on doing it (i.e. the ...\n",
      "Formulated question: What kind of action are you planning to take (e.g. running, studying, etc.), what's the intensity or value of that action (e.g. how fast, how much), and for how long do you plan on doing it (i.e. the duration)?\n",
      "\n",
      "For example, are you going to go for a casual 5-mile jog (action: jogging, value: 5 miles, duration: maybe an hour or so), or perhaps you're going to hit the books hard for a 3-hour study session (action: studying, value: intense focus, duration: 3 hours)?\n",
      "Node output status: waiting with formulated question\n",
      "\n",
      "Step 2 Output: What kind of action are you planning to take (e.g. running, studying, etc.), what's the intensity or value of that action (e.g. how fast, how much), and for how long do you plan on doing it (i.e. the duration)?\n",
      "\n",
      "For example, are you going to go for a casual 5-mile jog (action: jogging, value: 5 miles, duration: maybe an hour or so), or perhaps you're going to hit the books hard for a 3-hour study session (action: studying, value: intense focus, duration: 3 hours)?\n",
      "\n",
      "STEP 3: DEFINING ACTION TYPE\n",
      "\n",
      ">>> DEBUGGING TASK_IDENTIFIER NODE <<<\n",
      "Input messages: Target users with revenue greater than $1000 in the last month\n",
      "What kind of action are you planning to take (e.g. running, studying, etc.), what's the intensity or value of that action (e.g. how fast, how much), and for how long do you plan on doing it (i.e. the duration)?\n",
      "\n",
      "For example, are you going to go for a casual 5-mile jog (action: jogging, value: 5 miles, duration: maybe an hour or so), or perhaps you're going to hit the books hard for a 3-hour study session (action: studying, value: intense focus, duration: 3 hours)?\n",
      "i would like to offer bonus\n",
      "Prompt to LLM: Identify if this is a campaign-related request or general conversation based on the following messages:\n",
      "Target users with revenue greater than $1000 in the last month\n",
      "What kind of action are you planning to take (e.g. running, studying, etc.), what's the intensity or value of that action (e.g. how fast, how much), and for how long do you plan on doing it (i.e. the duration)?\n",
      "\n",
      "For example, are you going to go for a casual 5-mile jog (action: jogging, value: 5 miles, duration: maybe an hour or so), or perhaps you're going to hit the books hard for a 3-hour study session (action: studying, value: intense focus, duration: 3 hours)?\n",
      "i would like to offer bonus\n",
      "Task identification result: task_type='campaign_convo' description=\"The conversation includes phrases like 'Target users with revenue greater than $1000 in the last month' and 'i would like to offer bonus', which suggest a campaign-related discussion.\"\n",
      "Node output: {'action': 'campaign_convo', 'output': 'Task identified as: campaign_convo'}\n",
      "\n",
      ">>> DEBUGGING CAMPAIGN_MANAGER NODE <<<\n",
      "Input state action: campaign_convo\n",
      "Input state status: waiting\n",
      "Campaign info exists: True\n",
      "Current step: action_type\n",
      "Current step status: waiting\n",
      "Last message: i would like to offer bonus\n",
      "Processing user response for waiting state\n",
      "--------- {}\n",
      "MISIIIIIIING ['action_type', 'value', 'duration']\n",
      "Validation prompt: \n",
      "        You are validating a user response for a marketing campaign setup.\n",
      "\n",
      "        \n",
      "\n",
      "        Context:\n",
      "        Extract and validate ONLY FROM THIS RESPONSE: \"i would like to offer bonus\"\n",
      "        Alre...\n",
      "Validation result: valid=False, reasoning=The response is missing required fields 'value' and 'duration', and 'action_type' is partially extra...\n",
      "Response validated as invalid, follow-up needed\n",
      "Node output action: end, with follow-up question\n",
      "\n",
      ">>> DEBUGGING ROUTER <<<\n",
      "Input state action: end\n",
      "Input state status: waiting\n",
      "Routing to END\n",
      "\n",
      "Step 3 Output: You mentioned you would like to offer a bonus, that's a great start. To set up your marketing campaign, could you please provide more details? What is the value of the bonus you'd like to offer, and for how many days would you like this bonus to be available?\n",
      "\n",
      "STEP 3: DEFINING ACTION TYPEfgdh\n",
      "\n",
      ">>> DEBUGGING TASK_IDENTIFIER NODE <<<\n",
      "Input messages: i would like to offer bonus\n",
      "You mentioned you would like to offer a bonus, that's a great start. To set up your marketing campaign, could you please provide more details? What is the value of the bonus you'd like to offer, and for how many days would you like this bonus to be available?\n",
      "10 days\n",
      "Prompt to LLM: Identify if this is a campaign-related request or general conversation based on the following messages:\n",
      "i would like to offer bonus\n",
      "You mentioned you would like to offer a bonus, that's a great start. To set up your marketing campaign, could you please provide more details? What is the value of the bonus you'd like to offer, and for how many days would you like this bonus to be available?\n",
      "10 days\n",
      "Task identification result: task_type='campaign_convo' description='The conversation is about setting up a marketing campaign with a bonus offer.'\n",
      "Node output: {'action': 'campaign_convo', 'output': 'Task identified as: campaign_convo'}\n",
      "\n",
      ">>> DEBUGGING CAMPAIGN_MANAGER NODE <<<\n",
      "Input state action: campaign_convo\n",
      "Input state status: waiting\n",
      "Campaign info exists: True\n",
      "Current step: action_type\n",
      "Current step status: waiting\n",
      "Last message: 10 days\n",
      "Processing user response for waiting state\n",
      "--------- {}\n",
      "MISIIIIIIING ['action_type', 'value', 'duration']\n",
      "Validation prompt: \n",
      "        You are validating a user response for a marketing campaign setup.\n",
      "\n",
      "        \n",
      "\n",
      "        Context:\n",
      "        Extract and validate ONLY FROM THIS RESPONSE: \"10 days\"\n",
      "        Already collected: {}\n",
      "  ...\n",
      "Validation result: valid=False, reasoning=The response '10 days' is missing 'action_type' and 'value'. It only contains a valid duration....\n",
      "Response validated as invalid, follow-up needed\n",
      "Node output action: end, with follow-up question\n",
      "\n",
      ">>> DEBUGGING ROUTER <<<\n",
      "Input state action: end\n",
      "Input state status: waiting\n",
      "Routing to END\n",
      "\n",
      "Step 3 Output: You mentioned '10 days', which is a valid duration. However, we still need to know what type of action you'd like to take (bonus or discount) and what value this action will have (e.g., 10%, $10, 10 dollars). Could you please provide this information?\n",
      "\n",
      "Current campaign step: action_type\n",
      "Collected info so far: {}\n"
     ]
    }
   ],
   "source": [
    "def test_campaign_flow():\n",
    "    \"\"\"Test the entire campaign flow with debugging at each step\"\"\"\n",
    "    print(\"\\n===== TESTING COMPLETE CAMPAIGN FLOW =====\\n\")\n",
    "    \n",
    "    # Step 1: Initialize campaign\n",
    "    config = {\"configurable\": {\"thread_id\": \"test_campaign_flow\"}}\n",
    "    input_message = HumanMessage(content=\"I want to create a campaign\")\n",
    "    initial_state = {\n",
    "        \"conversation_id\": \"test_campaign_flow\",\n",
    "        \"messages\": [input_message],\n",
    "        \"action\": None,\n",
    "        \"campaign_info\": None,\n",
    "        \"output\": \"\",\n",
    "        \"status\": \"pending\"\n",
    "    }\n",
    "    \n",
    "    print(\"STEP 1: INITIALIZING CAMPAIGN\")\n",
    "    res1 = graph.invoke(initial_state, config)\n",
    "    print(f\"\\nStep 1 Output: {res1['output']}\")\n",
    "    \n",
    "    # Step 2: Define target segment\n",
    "    print(\"\\nSTEP 2: DEFINING TARGET SEGMENT\")\n",
    "    segment_message = HumanMessage(content=\"Target users with revenue greater than $1000 in the last month\")\n",
    "    res1[\"messages\"].append(segment_message)\n",
    "    res2 = graph.invoke(res1, config)\n",
    "    print(f\"\\nStep 2 Output: {res2['output']}\")\n",
    "    \n",
    "    # Step 3: Define action type\n",
    "    print(\"\\nSTEP 3: DEFINING ACTION TYPE\")\n",
    "    action_message = HumanMessage(content=\"i would like to offer bonus\")\n",
    "    res2[\"messages\"].append(action_message)\n",
    "    res3 = graph.invoke(res2, config)\n",
    "    print(f\"\\nStep 3 Output: {res3['output']}\")\n",
    "\n",
    "     # Step 3: Define action type\n",
    "    print(\"\\nSTEP 3: DEFINING ACTION TYPEfgdh\")\n",
    "    action_message = HumanMessage(content=\"10 days\")\n",
    "    res3[\"messages\"].append(action_message)\n",
    "    res4 = graph.invoke(res3, config)\n",
    "    print(f\"\\nStep 3 Output: {res4['output']}\")\n",
    "    \n",
    "    # Extract campaign info for inspection\n",
    "    if res4.get(\"campaign_info\"):\n",
    "        campaign_info = res4[\"campaign_info\"]\n",
    "        current_step_name = campaign_info.current_step\n",
    "        current_step = campaign_info.steps[current_step_name]\n",
    "        print(f\"\\nCurrent campaign step: {current_step_name}\")\n",
    "        print(f\"Collected info so far: {json.dumps(current_step.collected_info, indent=2)}\")\n",
    "    \n",
    "    return res4\n",
    "\n",
    "# Run the test\n",
    "campaign_state = test_campaign_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ddb08-11ab-4fe6-8f18-c6b2533e0c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698d2cd7-edba-4dec-9586-e0c3023c1b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5ec3b7-fcd1-45d3-b122-1540f6177429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d030ea9d-c503-42f1-b61a-6358ad7f845c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c781bf-bf07-4dff-b325-d6cb8581db98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
